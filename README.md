# LLM Finetuning

### In this Project I :

* Finetuned GPT2 with LoRA
* Used MLFlow for experiments tracking and reproducibility
* Deployed the finetuned LLM with Fast API

![Screenshot 2024-12-15 233216](https://github.com/user-attachments/assets/8a583af4-34b3-4e9a-97e5-b0728dc81808)
![Screenshot 2024-12-16 082203](https://github.com/user-attachments/assets/9415a595-1ec9-4099-add5-b30ae0f4a1d0)


## TODO
- [X] getting a working finetuning pipeline
- [X] using LoRA and QLoRA
- [X] using mlflow

  - [X] using normal tracking techniques
  - [X] using inference and testing in mlflow
  - [ ] using mlflow serve
- [ ] trying different finetuning techniques
- [X] Deployment using Fast API
- [ ] preparing the project to be a template for different finetuning projects
- [ ] using the a finetuned model in RAG pipeline
- [ ] simple UI to chat with documents
- [ ] converting to onnx .......
